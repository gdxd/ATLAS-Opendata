{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#How-to-rediscover-the-Higgs-boson-yourself!\" data-toc-modified-id=\"How-to-rediscover-the-Higgs-boson-yourself!-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>How to rediscover the Higgs boson yourself!</a></span><ul class=\"toc-item\"><li><span><a href=\"#Running-a-Jupyter-notebook\" data-toc-modified-id=\"Running-a-Jupyter-notebook-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Running a Jupyter notebook</a></span></li><li><span><a href=\"#First-time-setup-on-your-computer-(no-need-on-mybinder)\" data-toc-modified-id=\"First-time-setup-on-your-computer-(no-need-on-mybinder)-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>First time setup on your computer (no need on mybinder)</a></span></li><li><span><a href=\"#To-setup-everytime\" data-toc-modified-id=\"To-setup-everytime-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>To setup everytime</a></span></li><li><span><a href=\"#Lumi,-fraction,-file-path\" data-toc-modified-id=\"Lumi,-fraction,-file-path-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Lumi, fraction, file path</a></span></li><li><span><a href=\"#Samples\" data-toc-modified-id=\"Samples-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Samples</a></span></li><li><span><a href=\"#Changing-a-cut\" data-toc-modified-id=\"Changing-a-cut-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Changing a cut</a></span></li><li><span><a href=\"#Applying-a-cut\" data-toc-modified-id=\"Applying-a-cut-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Applying a cut</a></span></li><li><span><a href=\"#Plotting\" data-toc-modified-id=\"Plotting-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Plotting</a></span></li><li><span><a href=\"#What-can-you-do-to-explore-this-analysis?\" data-toc-modified-id=\"What-can-you-do-to-explore-this-analysis?-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>What can you do to explore this analysis?</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><img src=\"../../images/ATLASOD.gif\" style=\"width:50%\"></CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to rediscover the Higgs boson yourself!\n",
    "This notebook uses ATLAS Open Data http://opendata.atlas.cern to show you the steps to rediscover the Higgs boson yourself!\n",
    "\n",
    "ATLAS Open Data provides open access to proton-proton collision data at the LHC for educational purposes. ATLAS Open Data resources are ideal for high-school, undergraduate and postgraduate students.\n",
    "\n",
    "Notebooks are web applications that allow you to create and share documents that can contain for example:\n",
    "1. live code\n",
    "2. visualisations\n",
    "3. narrative text\n",
    "\n",
    "This analysis loosely follows the discovery of the Higgs boson by ATLAS https://arxiv.org/pdf/1207.7214.pdf (mostly Section 5 and 5.1)\n",
    "\n",
    "By the end of this notebook you will be able to:\n",
    "1. rediscover the Higgs boson yourself!\n",
    "2. know some general principles of a particle physics analysis\n",
    "\n",
    "Feynman diagram pictures are borrowed from our friends at https://www.particlezoo.net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><img src=\"images/feynman_diagrams/Hyy_feynman.png\" style=\"width:40%\"></CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='contents'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents: \n",
    "\n",
    "[Running a Jupyter notebook](#running) <br />\n",
    "[First time setup on your computer (no need on mybinder)](#setup_computer) <br />\n",
    "[To setup everytime](#setup_everytime) <br />\n",
    "[Lumi, fraction, file path](#fraction) <br />\n",
    "[Samples](#samples) <br />\n",
    "[Changing a cut](#changing_cut) <br />\n",
    "[Applying a cut](#applying_cut) <br />\n",
    "[Plotting](#plotting) <br />\n",
    "[What can you do to explore this analysis?](#going_further) <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='running'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a Jupyter notebook\n",
    "\n",
    "To run the whole Jupyter notebook, in the top menu click Cell -> Run All.\n",
    "\n",
    "To propagate a change you've made to a piece of code, click Cell -> Run All Below.\n",
    "\n",
    "You can also run a single code cell, by clicking Cell -> Run Cells, or using the keyboard shortcut Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup_computer'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First time setup on your computer (no need on mybinder)\n",
    "This first cell only needs to be run the first time you open this notebook on your computer. \n",
    "\n",
    "If you close Jupyter and re-open on the same computer, you won't need to run this first cell again.\n",
    "\n",
    "If you open on binder, you don't need to run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade --user pip # update the pip package installer\n",
    "!{sys.executable} -m pip install -U numpy pandas uproot3 matplotlib lmfit --user # install required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup_everytime'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To setup everytime\n",
    "Cell -> Run All Below\n",
    "\n",
    "to be done every time you re-open this notebook\n",
    "\n",
    "We're going to be using a number of tools to help us:\n",
    "* uproot: lets us read .root files typically used in particle physics into data formats used in python\n",
    "* pandas: lets us store data as dataframes, a format widely used in python\n",
    "* numpy: provides numerical calculations such as histogramming\n",
    "* matplotlib: common tool for making plots, figures, images, visualisations\n",
    "* lmfit: tool for statistical fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot3 # for reading .root files\n",
    "import pandas as pd # to store data as dataframe\n",
    "import time # to measure time to analyse\n",
    "import math # for mathematical functions such as square root\n",
    "import numpy as np # # for numerical calculations such as histogramming\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "from matplotlib.ticker import MaxNLocator,AutoMinorLocator # for minor ticks\n",
    "from lmfit.models import PolynomialModel, GaussianModel # for the signal and background fits\n",
    "import lmfit\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fraction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lumi, fraction, file path\n",
    "\n",
    "General definitions of luminosity, fraction of data used, where to access the input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls Input/GamGam/Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lumi = 0.5 # fb-1 # data_A only\n",
    "#lumi = 1.9 # fb-1 # data_B only\n",
    "#lumi = 2.9 # fb-1 # data_C only\n",
    "#lumi = 4.7 # fb-1 # data_D only\n",
    "#lumi = 10 # fb-1 # data_A,data_B,data_C,data_D\n",
    "\n",
    "lumis = [0.5, 1.9, 2.9, 4.7]\n",
    "\n",
    "fraction = 1.0 # reduce this is you want the code to run quicker\n",
    "\n",
    "tuple_path = \"Input/GamGam/Data/\" # local \n",
    "#tuple_path = \"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/GamGam/Data/\" # web address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='samples'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples\n",
    "\n",
    "Samples to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_list = ['data_A', 'data_B', 'data_C','data_D'] # add if you want more data\n",
    "fs = 0\n",
    "ls = 4\n",
    "samples_list = samples_list[fs:ls]\n",
    "lumi = sum(lumis[fs:ls])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to get data from files\n",
    "\n",
    "The datasets used in this notebook have already been filtered to include at least 2 photons per event, so that processing is quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_files():\n",
    "\n",
    "    frames = [] # define empty list to hold data\n",
    "    for val in samples_list: # loop over each file\n",
    "        fileString = tuple_path+val+\".GamGam.root\" # file name to open\n",
    "        temp = read_file(fileString,val) # call the function read_file defined below\n",
    "        frames.append(temp) # append dataframe returned from read_file to list of dataframes\n",
    "    data = pd.concat(frames) # concatenate list of dataframes together into one dataframe\n",
    "    \n",
    "    return data # return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to calculate diphoton invariant mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_myy(photon_pt,photon_eta,photon_phi,photon_E):\n",
    "    # first photon is [0], 2nd photon is [1] etc\n",
    "    px_0 = photon_pt[0]*math.cos(photon_phi[0]) # x-component of photon[0] momentum\n",
    "    py_0 = photon_pt[0]*math.sin(photon_phi[0]) # y-component of photon[0] momentum\n",
    "    pz_0 = photon_pt[0]*math.sinh(photon_eta[0]) # z-component of photon[0] momentum\n",
    "    px_1 = photon_pt[1]*math.cos(photon_phi[1]) # x-component of photon[1] momentum\n",
    "    py_1 = photon_pt[1]*math.sin(photon_phi[1]) # y-component of photon[1] momentum\n",
    "    pz_1 = photon_pt[1]*math.sinh(photon_eta[1]) # z-component of photon[1] momentum\n",
    "    sumpx = px_0 + px_1 # x-component of diphoton momentum\n",
    "    sumpy = py_0 + py_1 # y-component of diphoton momentum\n",
    "    sumpz = pz_0 + pz_1 # z-component of diphoton momentum \n",
    "    sump = math.sqrt(sumpx**2 + sumpy**2 + sumpz**2) # magnitude of diphoton momentum \n",
    "    sumE = photon_E[0] + photon_E[1] # energy of diphoton system\n",
    "    return math.sqrt(sumE**2 - sump**2)/1000 #/1000 to go from MeV to GeV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='changing_cut'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing a cut\n",
    "\n",
    "If you change a cut: Cell -> Run All Below\n",
    "\n",
    "If you change a cut here, you also need to make sure the cut is applied in the \"[Applying a cut](#applying_cut)\" cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut on photon reconstruction quality\n",
    "# paper: \"Photon candidates are required to pass identification criteria\"\n",
    "def cut_photon_reconstruction(photon_isTightID):\n",
    "# isTightID==True means a photon identified as being well reconstructed\n",
    "# want to keep events where True for both photons\n",
    "# first photon is [0], 2nd photon is [1] etc\n",
    "    return photon_isTightID[0]==True and photon_isTightID[1]==True\n",
    "    \n",
    "# Cut on Transverse momentum\n",
    "# paper: \"The leading (sub-leading) photon candidate is required to have ET > 40 GeV (30 GeV)\"\n",
    "def cut_photon_pt(photon_pt):\n",
    "# want to keep events where photon_pt[0]>40000 MeV and photon_pt[1]>30000 MeV\n",
    "    return photon_pt[0]>40000 and photon_pt[1]>30000\n",
    "\n",
    "# Cut on energy isolation\n",
    "# paper: \"Photon candidates are required to have an isolation transverse energy of less than 4 GeV\"\n",
    "def cut_isolation_et(photon_etcone20):\n",
    "# want to keep events where isolation eT<4000 MeV\n",
    "    return photon_etcone20[0]<4000 and photon_etcone20[1]<4000\n",
    "\n",
    "# Cut on pseudorapidity in barrel/end-cap transition region\n",
    "# paper: \"excluding the calorimeter barrel/end-cap transition region 1.37 < |η| < 1.52\"\n",
    "def cut_photon_eta_transition(photon_eta):\n",
    "# want to keep events where modulus of photon_eta is outside the range 1.37 to 1.52\n",
    "    return (abs(photon_eta[0])>1.52 or abs(photon_eta[0])<1.37) and (abs(photon_eta[1])>1.52 or abs(photon_eta[1])<1.37)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='applying_cut'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a cut \n",
    "\n",
    "If you add a cut: Cell -> Run All Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path,sample):\n",
    "    start = time.time() # start the clock\n",
    "    print(\"Processing: \"+sample) # print which sample is being processed\n",
    "    data_all = pd.DataFrame() # define empty pandas DataFrame to hold all data for this sample\n",
    "    tree = uproot3.open(path)[\"mini\"] # open the tree called mini\n",
    "    numevents = uproot3.numentries(path, \"mini\") # number of events\n",
    "    for data in tree.iterate([\"photon_pt\",\"photon_eta\",\"photon_phi\",\"photon_E\",\n",
    "                            \"photon_isTightID\",\"photon_etcone20\"], # add more variables here if you want to use them\n",
    "                           outputtype=pd.DataFrame, # choose output type as pandas DataFrame\n",
    "                           entrystop=numevents*fraction): # process up to numevents*fraction\n",
    "\n",
    "        nIn = len(data.index) # number of events in this batch\n",
    "        \n",
    "        # Cut on photon reconstruction quality using the function cut_photon_reconstruction defined above\n",
    "        data = data[ np.vectorize(cut_photon_reconstruction)(data.photon_isTightID)]\n",
    "        \n",
    "        # Cut on transverse momentum of the photons using the function cut_photon_pt defined above\n",
    "        data = data[ np.vectorize(cut_photon_pt)(data.photon_pt)]\n",
    "        \n",
    "        # Cut on energy isolation using the function cut_isolation_et defined above\n",
    "        data = data[ np.vectorize(cut_isolation_et)(data.photon_etcone20)]\n",
    "        \n",
    "        # Cut on pseudorapidity inside barrel/end-cap transition region using the function cut_photon_eta_transition\n",
    "        data = data[ np.vectorize(cut_photon_eta_transition)(data.photon_eta)]\n",
    "        \n",
    "        # Calculate reconstructed diphoton invariant mass using the function calc_myy defined above\n",
    "        data['myy'] = np.vectorize(calc_myy)(data.photon_pt,data.photon_eta,data.photon_phi,data.photon_E)\n",
    "        \n",
    "        # dataframe contents can be printed at any stage like this\n",
    "        #print(data)\n",
    "\n",
    "        # dataframe column can be printed at any stage like this\n",
    "        #print(data['photon_pt'])\n",
    "\n",
    "        # multiple dataframe columns can be printed at any stage like this\n",
    "        #print(data[['photon_pt','photon_eta']])\n",
    "\n",
    "        nOut = len(data.index) # number of events passing cuts in this batch\n",
    "        data_all = data_all.append(data) # append dataframe from this batch to the dataframe for the whole sample\n",
    "        elapsed = time.time() - start # time taken to process\n",
    "        print(\"\\t nIn: \"+str(nIn)+\",\\t nOut: \\t\"+str(nOut)+\"\\t in \"+str(round(elapsed,1))+\"s\") # events before and after\n",
    "    \n",
    "    return data_all # return dataframe containing events passing all cuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the processing happens (this will take some minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time() # time at start of whole processing\n",
    "data = get_data_from_files() # process all files\n",
    "elapsed = time.time() - start # time after whole processing\n",
    "print(\"Time taken: \"+str(round(elapsed,1))+\"s\") # print total time taken to process every file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plotting'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "If you only want a make a change in the plot: Cell -> Run All Below\n",
    "\n",
    "Define function to plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data, xref = 0, npol=4):   \n",
    "\n",
    "    xmin = 100 # GeV\n",
    "    xmax = 160 # GeV\n",
    "    step_size = 2 # GeV\n",
    "    \n",
    "    bin_edges = np.arange(start=xmin, # The interval includes this value\n",
    "                     stop=xmax+step_size, # The interval doesn't include this value\n",
    "                     step=step_size ) # Spacing between values\n",
    "    bin_centres = np.arange(start=xmin+step_size/2, # The interval includes this value\n",
    "                            stop=xmax+step_size/2, # The interval doesn't include this value\n",
    "                            step=step_size ) # Spacing between values\n",
    "    \n",
    "    bin_centres_s = bin_centres - xref\n",
    "\n",
    "    data_x,_ = np.histogram(data['myy'], \n",
    "                            bins=bin_edges ) # histogram the data\n",
    "    data_x_errors = np.sqrt( data_x ) # statistical error on the data\n",
    "\n",
    "    # data fit\n",
    "    polynomial_mod = PolynomialModel( npol ) # 4th order polynomial\n",
    "    polpnames = polynomial_mod.param_names\n",
    "    gaussian_mod = GaussianModel() # Gaussian\n",
    "    \n",
    "    # set initial guesses for the parameters of the polynomial model\n",
    "    # c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "    pars = polynomial_mod.guess(data_x, # data to use to guess parameter values\n",
    "                                x=bin_centres_s, c0=data_x.max(), c1=0,\n",
    "                                c2=0, c3=0, c4=0 )\n",
    "    \n",
    "    # set initial guesses for the parameters of the Gaussian model\n",
    "    pars += gaussian_mod.guess(data_x, # data to use to guess parameter values\n",
    "                               x=bin_centres_s, amplitude=100, \n",
    "                               center=125-xref, sigma=2 )\n",
    "    \n",
    "    model = polynomial_mod + gaussian_mod # combined model\n",
    "    \n",
    "    # fit the model to the data\n",
    "    out = model.fit(data_x, # data to be fit\n",
    "                    pars, # guesses for the parameters\n",
    "                    x=bin_centres_s, weights=1/data_x_errors ) \n",
    "\n",
    "    # background part of fit\n",
    "    params_dict = out.params.valuesdict() # get the parameters from the fit to data\n",
    "    \n",
    "    #c0 = params_dict['c0'] # c0 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "    #c1 = params_dict['c1'] # c1 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "    #c2 = params_dict['c2'] # c2 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "    #c3 = params_dict['c3'] # c3 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "    #c4 = params_dict['c4'] # c4 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "    \n",
    "    # get the background only part of the fit to data\n",
    "    #background = c0 + c1*bin_centres_s + c2*bin_centres_s**2 + c3*bin_centres_s**3 + c4*bin_centres_s**4\n",
    "\n",
    "    cpars = [ params_dict[x] for x in polpnames]\n",
    "    background = np.polyval( cpars[::-1],bin_centres_s)\n",
    "\n",
    "    # data fit - background fit = signal fit\n",
    "    signal_x = data_x - background \n",
    "\n",
    "\n",
    "    # *************\n",
    "    # Main plot \n",
    "    # *************\n",
    "    plt.axes([0.1,0.3,0.85,0.65]) # left, bottom, width, height \n",
    "    main_axes = plt.gca() # get current axes\n",
    "    \n",
    "    # plot the data points\n",
    "    main_axes.errorbar(x=bin_centres, y=data_x, yerr=data_x_errors, \n",
    "                       fmt='ko', # 'k' means black and 'o' means circles\n",
    "                       label='Data' ) \n",
    "    \n",
    "    # plot the signal + background fit\n",
    "    main_axes.plot(bin_centres, # x\n",
    "                   out.best_fit, # y\n",
    "                   '-r', # single red line\n",
    "                   label='Sig+Bkg Fit ($m_H=125$ GeV)' )\n",
    "    \n",
    "    # plot the background only fit\n",
    "    main_axes.plot(bin_centres, # x\n",
    "                   background, # y\n",
    "                   '--r', # dashed red line\n",
    "                   label='Bkg (4th order polynomial)' )\n",
    "\n",
    "    # set the x-limit of the main axes\n",
    "    main_axes.set_xlim( left=xmin, right=xmax ) \n",
    "    \n",
    "    # separation of x-axis minor ticks\n",
    "    main_axes.xaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "    \n",
    "    # set the axis tick parameters for the main axes\n",
    "    main_axes.tick_params(which='both', # ticks on both x and y axes\n",
    "                          direction='in', # Put ticks inside and outside the axes\n",
    "                          top=True, # draw ticks on the top axis\n",
    "                          labelbottom=False, # don't draw tick labels on bottom axis\n",
    "                          right=True ) # draw ticks on right axis\n",
    "    \n",
    "    # write y-axis label for main axes\n",
    "    main_axes.set_ylabel('Events / '+str(step_size)+' GeV', \n",
    "                         horizontalalignment='right') \n",
    "    \n",
    "    # set the y-axis limit for the main axes\n",
    "    main_axes.set_ylim( bottom=0, top=np.amax(data_x)*1.1 ) \n",
    "    \n",
    "    # set minor ticks on the y-axis of the main axes\n",
    "    main_axes.yaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "    \n",
    "    # avoid displaying y=0 on the main axes\n",
    "    main_axes.yaxis.get_major_ticks()[0].set_visible(False) \n",
    "\n",
    "    # Add text 'ATLAS Open Data' on plot\n",
    "    plt.text(0.2, # x\n",
    "             0.92, # y\n",
    "             'ATLAS Open Data', # text\n",
    "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "             fontsize=13 ) \n",
    "    \n",
    "    # Add text 'for education' on plot\n",
    "    plt.text(0.2, # x\n",
    "             0.86, # y\n",
    "             'for education', # text\n",
    "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "             style='italic',\n",
    "             fontsize=8 ) \n",
    "    \n",
    "    # Add energy and luminosity\n",
    "    lumi_used = str(lumi*fraction) # luminosity to write on the plot\n",
    "    plt.text(0.2, # x\n",
    "             0.8, # y\n",
    "             '$\\sqrt{s}$=13 TeV,$\\int$L dt = '+lumi_used+' fb$^{-1}$', # text\n",
    "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes \n",
    "    \n",
    "    # Add a label for the analysis carried out\n",
    "    plt.text(0.2, # x\n",
    "             0.74, # y\n",
    "             r'$H \\rightarrow \\gamma\\gamma$', # text \n",
    "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes\n",
    "\n",
    "    # draw the legend\n",
    "    main_axes.legend(frameon=False, # no box around the legend\n",
    "                     loc='lower left' ) # legend location \n",
    "\n",
    "\n",
    "    # *************\n",
    "    # Data-Bkg plot \n",
    "    # *************\n",
    "    plt.axes([0.1,0.1,0.85,0.2]) # left, bottom, width, height\n",
    "    sub_axes = plt.gca() # get the current axes\n",
    "    \n",
    "    # set the y axis to be symmetric about Data-Background=0\n",
    "    sub_axes.yaxis.set_major_locator( MaxNLocator(nbins='auto', \n",
    "                                                  symmetric=True) )\n",
    "    \n",
    "    # plot Data-Background\n",
    "    sub_axes.errorbar(x=bin_centres, y=signal_x, yerr=data_x_errors,\n",
    "                      fmt='ko' ) # 'k' means black and 'o' means circles\n",
    "    \n",
    "    # draw the fit to data\n",
    "    sub_axes.plot(bin_centres, # x\n",
    "                  out.best_fit-background, # y\n",
    "                  '-r' ) # single red line\n",
    "    \n",
    "    # draw the background only fit\n",
    "    sub_axes.plot(bin_centres, # x\n",
    "                  background-background, # y\n",
    "                  '--r' )  # dashed red line\n",
    "    \n",
    "    # set the x-axis limits on the sub axes\n",
    "    sub_axes.set_xlim( left=xmin, right=xmax ) \n",
    "    \n",
    "    # separation of x-axis minor ticks\n",
    "    sub_axes.xaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "    \n",
    "    # x-axis label\n",
    "    sub_axes.set_xlabel(r'di-photon invariant mass $\\mathrm{m_{\\gamma\\gamma}}$ [GeV]',\n",
    "                        x=1, horizontalalignment='right', \n",
    "                        fontsize=13 ) \n",
    "    \n",
    "    # set the tick parameters for the sub axes\n",
    "    sub_axes.tick_params(which='both', # ticks on both x and y axes\n",
    "                         direction='in', # Put ticks inside and outside the axes\n",
    "                         top=True, # draw ticks on the top axis\n",
    "                         right=True ) # draw ticks on right axis \n",
    "    \n",
    "    # separation of y-axis minor ticks\n",
    "    sub_axes.yaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "    \n",
    "    # y-axis label on the sub axes\n",
    "    sub_axes.set_ylabel( 'Events-Bkg' ) \n",
    "\n",
    "\n",
    "    # Generic features for both plots\n",
    "    main_axes.yaxis.set_label_coords( -0.09, 1 ) # x,y coordinates of the y-axis label on the main axes\n",
    "    sub_axes.yaxis.set_label_coords( -0.09, 0.5 ) # x,y coordinates of the y-axis label on the sub axes\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function to plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data),sum(data.myy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fit_out = plot_data(data, xref = 130,npol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_out.success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit_out.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def cov2cor( cov):\n",
    "    x,y = cov.shape\n",
    "    \n",
    "    if x != y:\n",
    "        print('cov2cor error: non-square matrix', cov.shape)\n",
    "        return None\n",
    "    diags = [math.sqrt(cov[i,i]) for i in range(x) ]\n",
    "    cor = cov.copy()\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            cor[i,j] = cov[i,j]/(diags[i]*diags[j])\n",
    "    return cor\n",
    "def print_cor( cor ):\n",
    "    x,y = cor.shape\n",
    "    \n",
    "    if x != y:\n",
    "        print('print_cor error: non-square matrix', cov.shape)\n",
    "        return None\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            print( f\"{cor[i,j]:6.3f} \", end='')\n",
    "        print('')\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = cov2cor(fit_out.covar)\n",
    "print_cor(cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='going_further'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can you do to explore this analysis?\n",
    "\n",
    "* Increase the fraction of data used in '[Lumi, fraction, file path](#fraction)'\n",
    "* Use data_B, data_C and data_D in '[Samples](#samples)'\n",
    "* Check how many events are being thrown away by each cut in '[Applying a cut](#applying_cut)'\n",
    "* Add more cuts from the [Higgs discovery paper](https://www.sciencedirect.com/science/article/pii/S037026931200857X#se0090) in '[Changing a cut](#changing_cut)' and '[Applying a cut](#applying_cut)'\n",
    "* Find the reduced chi-squared for the fit in '[Plotting](#plotting)'\n",
    "* Find the mean of the fitted Gaussian in '[Plotting](#plotting)'\n",
    "* Find the width of the fitted Gaussian in '[Plotting](#plotting)'\n",
    "* Try different initial guesses for the parameters of the fit in '[Plotting](#plotting)'\n",
    "* Try different functions for the fit in '[Plotting](#plotting)'\n",
    "* Your idea!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
